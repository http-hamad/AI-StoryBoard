{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from dotenv import load_dotenv\n",
    "from PIL import Image\n",
    "import requests\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "from groq import Groq\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "deepseek_api_key = os.getenv(\"DEEPSEEK_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Image captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BLIP processor and model\n",
    "processor = BlipProcessor.from_pretrained(\"Sof22/image-caption-large-copy\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Sof22/image-caption-large-copy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate captions for multiple images\n",
    "def generate_captions(image_paths):\n",
    "    images = [Image.open(img_path).convert(\"RGB\") for img_path in image_paths]  # Load all images\n",
    "    inputs = processor(images=images, return_tensors=\"pt\", padding=True)  # Preprocess in batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        caption_ids = model.generate(**inputs)  # Generate captions for all images\n",
    "\n",
    "    captions = [processor.decode(caption_ids[i], skip_special_tokens=True) for i in range(len(image_paths))]  # Decode captions\n",
    "    return captions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: hi.jpg -> Caption: there is a man sitting on a chair in a room with a red tie and glasses on his head\n",
      "Image: img.jpg -> Caption: araffe standing in front of a church with a sky background and a person holding a cell phone\n",
      "Image: imgg.jpg -> Caption: arafed man in a button down shirt and black pants standing in front of a curtain and smiling\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "image_paths = [\"hi.jpg\", \"img.jpg\", \"imgg.jpg\"]  # Replace with actual image paths\n",
    "captions = generate_captions(image_paths)\n",
    "\n",
    "# Print the captions\n",
    "caption = []\n",
    "for img, cap in zip(image_paths, captions):\n",
    "    print(f\"Image: {img} -> Caption: {cap}\")\n",
    "    caption.append(cap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating LLM for story generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The man in the red tie, perched on the worn armchair, adjusted his glasses perched precariously on his head.  The room, dim and dusty, reflected the twilight of his life.  He traced the faded floral pattern on the armchair fabric, a stark contrast to the vibrant red of his tie – a tie he’d worn to his daughter's wedding, a wedding he’d barely remembered, the details blurred by the creeping fog of his dementia.  A photograph sat on the table beside him, a faded image of a giraffe, impossibly graceful, standing before a church. It was a picture his daughter had taken on a trip, a trip he'd longed to join but couldn't.  He remembered her laughter, bright and clear as the summer sky in the background of the photo, a sky he no longer truly saw.  Then, another memory flickered – a younger him, a man in a crisp button-down shirt and black pants, standing before a curtain, smiling a genuine, heartfelt smile.  He was about to go on stage, to play the clarinet, a melody he could no longer recall.  Now, only the hollow echo of that joyful sound remained. The phone in the giraffe photo, held by his daughter’s hand – a distant, unreachable connection to a life he was losing, a life of vibrant colour fading into the monochrome of his present reality.  The red tie felt heavy, a symbol of a joyous past he couldn't quite grasp. The giraffe, the church, the smile – all fading memories, as fleeting and fragile as the last vestiges of his mind.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genai.configure(api_key=gemini_api_key)\n",
    "model = genai.GenerativeModel(\"models/gemini-1.5-flash\")\n",
    "\n",
    "#settings of the story\n",
    "#length\n",
    "n = input(\"Enter the lenght of story to generate: \")\n",
    "#theme\n",
    "theme = input(\"Enter the theme of the story: \")\n",
    "\n",
    "# Generate text\n",
    "prompt = (f\"Write a minimum {n}-word long story about the following context {caption} and give it a touch of {theme}-theme.\"\n",
    "            \"Provide a response with the combined context of all the captions that make sense. Be creative and imaginative.\"\n",
    "            \"Start your response from the beginning of the story and conclude it at the end.\")\n",
    "\n",
    "result = model.generate_content(prompt)\n",
    "\n",
    "result = result.candidates[0].content.parts[0].text\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepSeek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once, there was a man named Harold, who found himself sitting in a dimly lit room, dressed in his usual red tie and glasses, though neither/detail seemed important that day. The room felt particularly empty, save for the quiet creak of the chair he sat on. There was a sense of weight in the air, a gravity he couldn’t escape. Across town, a giraffe stood in front of a church, its elegant neck turned as if scanning the horizon. The sky was pale, a soft pink blending into its grayish tones, an artist’s rendition of neither night nor day. In the foreground, a man stood with a phone in his hand, eternally paused in his pursuit of capturing the moment. \n",
      "\n",
      "As the day stretched, the space between purpose and drift widensedened. How anyone or anywhere arrived-there was not so much a mystery as an impossibility in such an intricate design. Behind a closed curtain at an assembly hall nearby—one not so much as approached by daylight—there he was, a buttoned-down figure with darkened teeth speaking. Though his brown eyes creased as he tilted mouth upwards, it was a tired motion, learned habit than indication of joy. Among blank walls in boardrooms as often at carnivals, a strained formality drew his lips forward again even as their edges began threatening to wither. The glass mirrored of a hall: nothing at once—because always doubling each image for to look more robust—mirrored him as little left half of whom he had himself allowed become; while life, as perhaps any, did continue turning if a single gear clicked each another—far from everything happening at edge speed on another track before catching up somehow.\n",
      "\n",
      "Is it funny? Endings—theirs (mine/yours/hers?)-but either side left alone as stories are not meant forever as each reader enters only where but to leave at what age and time—and in Harold's story’s perspective, the man and the tie didn’t leave that dim room—another perspective had no concept of so grand other ways as of light, day, nothing while on the church scene across—.\n",
      "\n",
      "Or wait no:\n",
      "\n",
      "(Writer's Apologies: in his narrative to write these pieces in collab to the events desired with the man, must a point emerge meaning more coherent linking would happen, if he at 72 degrees his tears). I think I've hit the time limit here, so conclude-- in a more detailed matter...\n",
      "\n",
      "*Sigh* sorry but time limit—. A more detailed look— tying in a final coherence and making sense, concluding that the sad things—final s—[End](10)\n"
     ]
    }
   ],
   "source": [
    "#settings of the story\n",
    "#length\n",
    "n = input(\"Enter the lenght of story to generate: \")\n",
    "#theme\n",
    "theme = input(\"Enter the theme of the story: \")\n",
    "\n",
    "client = Groq(api_key=deepseek_api_key)\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"deepseek-r1-distill-llama-70b\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (f\"\"\"Write a complete story of exactly {n} words about {caption} with a {theme} theme.\n",
    "    Story structure: Beginning, Middle, Conclusion\n",
    "    Omit any <think> tags or internal commentary\"\"\")\n",
    "        }\n",
    "    ],\n",
    "    temperature=1.5,\n",
    "    max_completion_tokens=1024,\n",
    "    top_p=0.95,\n",
    "    stream=True,\n",
    "    reasoning_format=\"raw\"\n",
    ")\n",
    "\n",
    "story_output = \"\"\n",
    "for chunk in completion:\n",
    "    story_output += chunk.choices[0].delta.content or \"\"\n",
    "\n",
    "# Remove text between <think> and </think>\n",
    "clean_story = re.sub(r\"<think>.*?</think>\", \"\", story_output, flags=re.DOTALL)\n",
    "\n",
    "# Print the final story\n",
    "print(clean_story.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blip_dep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
